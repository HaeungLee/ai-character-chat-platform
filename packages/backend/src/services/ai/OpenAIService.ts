// OpenAI ì„œë¹„ìŠ¤
import OpenAI from 'openai'
import { logger } from '../../utils/logger'

export interface OpenAIConfig {
  apiKey: string
  organization?: string
  model?: string
  temperature?: number
  maxTokens?: number
}

export interface ChatMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

export interface CharacterPrompt {
  name: string
  personality: string
  systemPrompt: string
  temperature?: number
}

// ğŸ†• ì‚¬ìš©ëŸ‰ ì •ë³´
export interface UsageInfo {
  promptTokens: number
  completionTokens: number
  totalTokens: number
  model: string
}

export class OpenAIService {
  private client: OpenAI
  private defaultModel: string
  private defaultTemperature: number
  private defaultMaxTokens: number
  
  // ğŸ†• ë§ˆì§€ë§‰ ìš”ì²­ì˜ ì‚¬ìš©ëŸ‰ ì •ë³´
  private _lastUsage: UsageInfo | null = null

  constructor(config: OpenAIConfig) {
    this.client = new OpenAI({
      apiKey: config.apiKey,
      organization: config.organization,
    })

    this.defaultModel = config.model || 'gpt-4'
    this.defaultTemperature = config.temperature || 0.7
    this.defaultMaxTokens = config.maxTokens || 1000
  }

  // ğŸ†• ë§ˆì§€ë§‰ ì‚¬ìš©ëŸ‰ ì¡°íšŒ
  get lastUsage(): UsageInfo | null {
    return this._lastUsage
  }

  // ğŸ†• ì‚¬ìš©ëŸ‰ ì´ˆê¸°í™”
  clearLastUsage(): void {
    this._lastUsage = null
  }

  // ìºë¦­í„° ê¸°ë°˜ ì±„íŒ… ì‘ë‹µ ìƒì„±
  async generateCharacterResponse(
    character: CharacterPrompt,
    userMessage: string,
    conversationHistory: ChatMessage[] = []
  ): Promise<string> {
    try {
      const messages: ChatMessage[] = [
        {
          role: 'system',
          content: this.buildCharacterSystemPrompt(character)
        },
        ...conversationHistory.slice(-10), // ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
        {
          role: 'user',
          content: userMessage
        }
      ]

      const response = await this.client.chat.completions.create({
        model: this.defaultModel,
        messages,
        temperature: character.temperature || this.defaultTemperature,
        max_tokens: this.defaultMaxTokens,
        presence_penalty: 0.6,
        frequency_penalty: 0.5,
      })

      // ğŸ†• ì‚¬ìš©ëŸ‰ ì €ì¥
      if (response.usage) {
        this._lastUsage = {
          promptTokens: response.usage.prompt_tokens,
          completionTokens: response.usage.completion_tokens,
          totalTokens: response.usage.total_tokens,
          model: response.model,
        }
      }

      const aiResponse = response.choices[0]?.message?.content
      if (!aiResponse) {
        throw new Error('AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
      }

      return aiResponse
    } catch (error) {
      logger.error('OpenAI ìºë¦­í„° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      throw new Error('AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
    }
  }

  // ğŸ†• ìºë¦­í„° ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (íƒ€ìê¸° íš¨ê³¼)
  async *generateCharacterResponseStream(
    character: CharacterPrompt,
    userMessage: string,
    conversationHistory: ChatMessage[] = []
  ): AsyncGenerator<string, void, unknown> {
    try {
      const messages: ChatMessage[] = [
        {
          role: 'system',
          content: this.buildCharacterSystemPrompt(character)
        },
        ...conversationHistory.slice(-10),
        {
          role: 'user',
          content: userMessage
        }
      ]

      const stream = await this.client.chat.completions.create({
        model: this.defaultModel,
        messages,
        temperature: character.temperature || this.defaultTemperature,
        max_tokens: this.defaultMaxTokens,
        presence_penalty: 0.6,
        frequency_penalty: 0.5,
        stream: true, // ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
      })

      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content
        if (content) {
          yield content
        }
      }
    } catch (error) {
      logger.error('OpenAI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      throw new Error('AI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
    }
  }

  // ğŸ†• ì¼ë°˜ ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
  async *generateChatResponseStream(
    messages: ChatMessage[],
    options?: {
      model?: string
      temperature?: number
      maxTokens?: number
    }
  ): AsyncGenerator<string, void, unknown> {
    try {
      const stream = await this.client.chat.completions.create({
        model: options?.model || this.defaultModel,
        messages,
        temperature: options?.temperature || this.defaultTemperature,
        max_tokens: options?.maxTokens || this.defaultMaxTokens,
        stream: true,
      })

      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content
        if (content) {
          yield content
        }
      }
    } catch (error) {
      logger.error('OpenAI ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      throw new Error('AI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
    }
  }

  // ì¼ë°˜ ì±„íŒ… ì‘ë‹µ ìƒì„±
  async generateChatResponse(
    messages: ChatMessage[],
    options?: {
      model?: string
      temperature?: number
      maxTokens?: number
    }
  ): Promise<string> {
    try {
      const response = await this.client.chat.completions.create({
        model: options?.model || this.defaultModel,
        messages,
        temperature: options?.temperature || this.defaultTemperature,
        max_tokens: options?.maxTokens || this.defaultMaxTokens,
      })

      // ğŸ†• ì‚¬ìš©ëŸ‰ ì €ì¥
      if (response.usage) {
        this._lastUsage = {
          promptTokens: response.usage.prompt_tokens,
          completionTokens: response.usage.completion_tokens,
          totalTokens: response.usage.total_tokens,
          model: response.model,
        }
      }

      const aiResponse = response.choices[0]?.message?.content
      if (!aiResponse) {
        throw new Error('AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
      }

      return aiResponse
    } catch (error) {
      logger.error('OpenAI ì±„íŒ… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      throw new Error('AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
    }
  }

  // ì´ë¯¸ì§€ ìƒì„± (DALL-E)
  async generateImage(
    prompt: string,
    options?: {
      size?: '256x256' | '512x512' | '1024x1024' | '1792x1024' | '1024x1792'
      quality?: 'standard' | 'hd'
      style?: 'vivid' | 'natural'
    }
  ): Promise<string> {
    try {
      const enhancedPrompt = this.enhanceImagePrompt(prompt)

      const response = await this.client.images.generate({
        model: 'dall-e-3',
        prompt: enhancedPrompt,
        size: options?.size || '1024x1024',
        quality: options?.quality || 'standard',
        style: options?.style || 'vivid',
        n: 1,
      })

      const imageUrl = response.data[0]?.url
      if (!imageUrl) {
        throw new Error('ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
      }

      return imageUrl
    } catch (error) {
      logger.error('OpenAI ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨:', error)
      throw new Error('ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
    }
  }

  // ìºë¦­í„° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
  private buildCharacterSystemPrompt(character: CharacterPrompt): string {
    return `You are ${character.name}. ${character.personality}.

Guidelines:
- Stay in character at all times
- Be engaging and natural in your responses
- Maintain the personality and behavior patterns described
- Keep responses appropriate and helpful
- If asked about your identity, maintain the character role
- Respond in Korean unless specifically asked to use another language

System Prompt: ${character.systemPrompt}

Remember: You are role-playing as ${character.name}. Stay consistent with the character's personality and background.`
  }

  // ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìµœì í™”
  private enhanceImagePrompt(prompt: string): string {
    return `${prompt}, high quality, detailed, professional, 8k, sharp focus, well lit`
  }

  // í† í° ìˆ˜ ê³„ì‚° (ëŒ€ëµ)
  estimateTokens(text: string): number {
    // ê°„ë‹¨í•œ í† í° ê³„ì‚° (ì‹¤ì œë¡œëŠ” tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥)
    return Math.ceil(text.length / 4)
  }

  // ì‚¬ìš©ëŸ‰ í™•ì¸
  async getUsage(): Promise<any> {
    try {
      // ì‹¤ì œë¡œëŠ” Stripeë‚˜ OpenAI Billing APIë¥¼ í†µí•´ ì‚¬ìš©ëŸ‰ ì¡°íšŒ
      // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ êµ¬í˜„
      return {
        totalTokens: 0,
        totalRequests: 0,
        costs: 0,
      }
    } catch (error) {
      logger.error('ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨:', error)
      return null
    }
  }
}
