# AI Provider í™•ì¥ì„± ë¦¬íŒ©í† ë§ ì„¤ê³„

> **ì‘ì„±ì¼:** 2024-12-13  
> **ìƒíƒœ:** ğŸ“‹ ê²€í†  ëŒ€ê¸° (í–¥í›„ êµ¬í˜„ ê³ ë ¤)  
> **ìš°ì„ ìˆœìœ„:** ë‚®ìŒ (í˜„ì¬ OpenRouterë¡œ ëŒ€ë¶€ë¶„ ì»¤ë²„ ê°€ëŠ¥)

---

## ğŸ“‹ ë°°ê²½

### í˜„ì¬ ìƒí™©

```
AIService
â”œâ”€â”€ OpenAIService      - GPT ëª¨ë¸ ì§ì ‘ ì—°ë™
â”œâ”€â”€ OpenRouterService  - ë‹¤ì–‘í•œ ëª¨ë¸ (Claude, Gemini, Llama ë“±)
â”œâ”€â”€ ReplicateService   - ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ìƒì„±
â””â”€â”€ StabilityAIService - Stable Diffusion
```

### OpenRouterì˜ ì¥ì 

OpenRouterë¥¼ í†µí•´ ì´ë¯¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:
- **Anthropic:** Claude 3.5 Sonnet, Claude 3 Opus
- **Google:** Gemini Pro, Gemini Flash
- **Meta:** Llama 3.3, Llama 3.2
- **Mistral:** Mistral Large, Mixtral
- **OpenAI:** GPT-4o, GPT-4 Turbo (í”„ë¡ì‹œ)

â†’ **ë³„ë„ Provider ì§ì ‘ ì—°ë™ ì—†ì´ë„ ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥**

---

## ğŸ¤” ì§ì ‘ ì—°ë™ vs OpenRouter ë¹„êµ

### ë¹„ìš© ë¹„êµ (1M í† í° ê¸°ì¤€, 2024ë…„ 12ì›”)

| ëª¨ë¸ | ì§ì ‘ ì—°ë™ | OpenRouter | ì°¨ì´ |
|------|-----------|------------|------|
| GPT-4o (input) | $2.50 | $2.50 | ë™ì¼ |
| GPT-4o (output) | $10.00 | $10.00 | ë™ì¼ |
| Claude 3.5 Sonnet (input) | $3.00 | $3.00 | ë™ì¼ |
| Claude 3.5 Sonnet (output) | $15.00 | $15.00 | ë™ì¼ |
| Gemini 1.5 Pro (input) | $1.25 | $1.25 | ë™ì¼ |

**ê²°ë¡ :** OpenRouterëŠ” ì›ê°€ + ë§ˆì§„ ì—†ì´ ì œê³µ (ëŒ€ë¶€ë¶„ ë™ì¼ ê°€ê²©)

### ì§ì ‘ ì—°ë™ì´ í•„ìš”í•œ ê²½ìš°

1. **Fine-tuning ì‚¬ìš© ì‹œ** - OpenAI/Anthropic ì§ì ‘ ì—°ë™ í•„ìš”
2. **Batch API** - OpenAI Batch API (50% í• ì¸)
3. **íŠ¹ìˆ˜ ê¸°ëŠ¥** - Assistants API, Function Calling ê³ ê¸‰ ê¸°ëŠ¥
4. **SLA/ë³´ì•ˆ ìš”êµ¬** - ì—”í„°í”„ë¼ì´ì¦ˆ ê³„ì•½ ì‹œ

### í˜„ì¬ íŒë‹¨

```
âœ… OpenRouter ìœ ì§€ - ëŒ€ë¶€ë¶„ì˜ use case ì»¤ë²„
âŒ ì§ì ‘ ì—°ë™ ë¦¬íŒ©í† ë§ - ë‹¹ì¥ ë¶ˆí•„ìš”
ğŸ“‹ ë¬¸ì„œí™” - í–¥í›„ í•„ìš” ì‹œ ì°¸ê³ 
```

---

## ğŸ—ï¸ í–¥í›„ ë¦¬íŒ©í† ë§ ì„¤ê³„ (ì°¸ê³ ìš©)

### Provider Interface

```typescript
// packages/backend/src/services/ai/providers/IAIProvider.ts

export interface IAIProvider {
  // Provider ì‹ë³„
  readonly name: string  // 'openai' | 'openrouter' | 'anthropic' | 'google'
  readonly displayName: string
  
  // ì±„íŒ… ìƒì„±
  generateChatResponse(
    messages: ChatMessage[],
    options: ChatOptions
  ): Promise<ChatResponse>
  
  // ìŠ¤íŠ¸ë¦¬ë°
  generateChatResponseStream(
    messages: ChatMessage[],
    options: ChatOptions
  ): AsyncGenerator<string>
  
  // ì„ë² ë”© (ì§€ì›í•˜ëŠ” ê²½ìš°)
  generateEmbedding?(text: string): Promise<number[]>
  
  // ì‚¬ìš©ëŸ‰ ì •ë³´ (ë¹„ìš© ê³„ì‚°ìš©)
  getLastUsage(): UsageInfo | null
  
  // ì§€ì› ëª¨ë¸ ëª©ë¡
  getAvailableModels(): ModelInfo[]
  
  // ìƒíƒœ í™•ì¸
  healthCheck(): Promise<HealthCheckResult>
}

export interface ChatMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

export interface ChatOptions {
  model: string
  temperature?: number
  maxTokens?: number
  topP?: number
  stream?: boolean
}

export interface ChatResponse {
  content: string
  usage: UsageInfo
  model: string
  finishReason: string
}

export interface UsageInfo {
  promptTokens: number
  completionTokens: number
  totalTokens: number
}

export interface ModelInfo {
  id: string
  name: string
  contextWindow: number
  inputPrice: number   // per 1K tokens
  outputPrice: number  // per 1K tokens
  capabilities: ('chat' | 'vision' | 'function' | 'embedding')[]
}
```

### Provider Registry

```typescript
// packages/backend/src/services/ai/ProviderRegistry.ts

class ProviderRegistry {
  private providers: Map<string, IAIProvider> = new Map()
  
  register(provider: IAIProvider): void {
    this.providers.set(provider.name, provider)
  }
  
  get(name: string): IAIProvider | undefined {
    return this.providers.get(name)
  }
  
  getAll(): IAIProvider[] {
    return Array.from(this.providers.values())
  }
  
  // ëª¨ë¸ IDë¡œ ì ì ˆí•œ Provider ì°¾ê¸°
  findProviderForModel(modelId: string): IAIProvider | undefined {
    for (const provider of this.providers.values()) {
      const models = provider.getAvailableModels()
      if (models.some(m => m.id === modelId)) {
        return provider
      }
    }
    return undefined
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
export const providerRegistry = new ProviderRegistry()

// ì´ˆê¸°í™”
providerRegistry.register(new OpenAIProvider(process.env.OPENAI_API_KEY))
providerRegistry.register(new OpenRouterProvider(process.env.OPENROUTER_API_KEY))
// í•„ìš” ì‹œ ì¶”ê°€
// providerRegistry.register(new AnthropicProvider(process.env.ANTHROPIC_API_KEY))
// providerRegistry.register(new GoogleProvider(process.env.GOOGLE_API_KEY))
```

### ìƒˆ Provider ì¶”ê°€ ì˜ˆì‹œ

```typescript
// packages/backend/src/services/ai/providers/AnthropicProvider.ts

import Anthropic from '@anthropic-ai/sdk'

export class AnthropicProvider implements IAIProvider {
  readonly name = 'anthropic'
  readonly displayName = 'Anthropic'
  
  private client: Anthropic
  private lastUsage: UsageInfo | null = null

  constructor(apiKey: string) {
    this.client = new Anthropic({ apiKey })
  }

  async generateChatResponse(
    messages: ChatMessage[], 
    options: ChatOptions
  ): Promise<ChatResponse> {
    const response = await this.client.messages.create({
      model: options.model || 'claude-3-5-sonnet-20241022',
      max_tokens: options.maxTokens || 4096,
      messages: messages.map(m => ({
        role: m.role === 'system' ? 'user' : m.role,
        content: m.content,
      })),
      system: messages.find(m => m.role === 'system')?.content,
    })

    this.lastUsage = {
      promptTokens: response.usage.input_tokens,
      completionTokens: response.usage.output_tokens,
      totalTokens: response.usage.input_tokens + response.usage.output_tokens,
    }

    return {
      content: response.content[0].type === 'text' 
        ? response.content[0].text 
        : '',
      usage: this.lastUsage,
      model: response.model,
      finishReason: response.stop_reason || 'stop',
    }
  }

  async *generateChatResponseStream(
    messages: ChatMessage[], 
    options: ChatOptions
  ): AsyncGenerator<string> {
    const stream = await this.client.messages.stream({
      model: options.model || 'claude-3-5-sonnet-20241022',
      max_tokens: options.maxTokens || 4096,
      messages: messages.map(m => ({
        role: m.role === 'system' ? 'user' : m.role,
        content: m.content,
      })),
      system: messages.find(m => m.role === 'system')?.content,
    })

    for await (const event of stream) {
      if (event.type === 'content_block_delta' && 
          event.delta.type === 'text_delta') {
        yield event.delta.text
      }
    }

    const finalMessage = await stream.finalMessage()
    this.lastUsage = {
      promptTokens: finalMessage.usage.input_tokens,
      completionTokens: finalMessage.usage.output_tokens,
      totalTokens: finalMessage.usage.input_tokens + finalMessage.usage.output_tokens,
    }
  }

  getLastUsage(): UsageInfo | null {
    return this.lastUsage
  }

  getAvailableModels(): ModelInfo[] {
    return [
      {
        id: 'claude-3-5-sonnet-20241022',
        name: 'Claude 3.5 Sonnet',
        contextWindow: 200000,
        inputPrice: 0.003,
        outputPrice: 0.015,
        capabilities: ['chat', 'vision'],
      },
      {
        id: 'claude-3-opus-20240229',
        name: 'Claude 3 Opus',
        contextWindow: 200000,
        inputPrice: 0.015,
        outputPrice: 0.075,
        capabilities: ['chat', 'vision'],
      },
    ]
  }

  async healthCheck(): Promise<HealthCheckResult> {
    try {
      // ê°„ë‹¨í•œ API í˜¸ì¶œë¡œ ìƒíƒœ í™•ì¸
      await this.client.messages.create({
        model: 'claude-3-haiku-20240307',
        max_tokens: 10,
        messages: [{ role: 'user', content: 'Hi' }],
      })
      return { healthy: true }
    } catch (error) {
      return { healthy: false, error: error.message }
    }
  }
}
```

---

## ğŸ“Š ì‚¬ìš©ëŸ‰ ì¶”ì  (í˜„ì¬ êµ¬í˜„ ê¶Œì¥)

### ì¦‰ì‹œ êµ¬í˜„ ê°€ëŠ¥í•œ ë²”ìœ„

ë¦¬íŒ©í† ë§ ì—†ì´ í˜„ì¬ êµ¬ì¡°ì—ì„œ ì‚¬ìš©ëŸ‰ ì¶”ì  ì¶”ê°€:

```typescript
// ê¸°ì¡´ OpenAIService, OpenRouterServiceì— ì¶”ê°€

class OpenAIService {
  private usageTracker: UsageTrackingService
  
  async generateChatCompletion(...) {
    const response = await this.client.chat.completions.create(...)
    
    // ğŸ†• ì‚¬ìš©ëŸ‰ ê¸°ë¡
    await this.usageTracker.recordUsage({
      provider: 'openai',
      model: options.model,
      promptTokens: response.usage.prompt_tokens,
      completionTokens: response.usage.completion_tokens,
      userId,
      requestType: 'chat',
    })
    
    return response
  }
}
```

### DB ìŠ¤í‚¤ë§ˆ (ìµœì†Œ)

```prisma
model AIUsageLog {
  id                String   @id @default(cuid())
  userId            String
  provider          String   // 'openai' | 'openrouter'
  model             String
  promptTokens      Int
  completionTokens  Int
  totalTokens       Int
  costUsd           Decimal  @db.Decimal(10, 6)
  requestType       String   // 'chat' | 'image' | 'embedding'
  characterId       String?
  chatId            String?
  isSuccess         Boolean  @default(true)
  createdAt         DateTime @default(now())
  
  @@index([userId, createdAt])
  @@index([provider, createdAt])
}
```

---

## ğŸ“‹ ê²°ì • ì‚¬í•­

### í˜„ì¬ (2024-12)

| í•­ëª© | ê²°ì • |
|------|------|
| Provider ë¦¬íŒ©í† ë§ | âŒ ë³´ë¥˜ (OpenRouterë¡œ ì¶©ë¶„) |
| ì‚¬ìš©ëŸ‰ ì¶”ì  | âœ… êµ¬í˜„ (AIUsageLog í…Œì´ë¸”) |
| ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ | âœ… êµ¬í˜„ (ê¸°ë³¸ ì§‘ê³„ API) |
| ì§ì ‘ ì—°ë™ (Claude/Gemini) | âŒ ë³´ë¥˜ (OpenRouter í™œìš©) |

### í–¥í›„ íŠ¸ë¦¬ê±°

ì§ì ‘ ì—°ë™ ë¦¬íŒ©í† ë§ì´ í•„ìš”í•œ ì‹œì :
1. Fine-tuning ëª¨ë¸ ì‚¬ìš© í•„ìš”
2. OpenRouter ê°€ê²© ì •ì±… ë³€ê²½
3. íŠ¹ì • Provider ì „ìš© ê¸°ëŠ¥ í•„ìš”
4. ì—”í„°í”„ë¼ì´ì¦ˆ SLA ìš”êµ¬

---

## ğŸ“ ê´€ë ¨ ë¬¸ì„œ

- `1213_analize.md` - ì „ì²´ í”„ë¡œì íŠ¸ ë¶„ì„
- `1213_VectorDB.md` - ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì„¤ê³„
- `1212_LoRA.md` - ì»¤ìŠ¤í…€ ëª¨ë¸ ê³„íš


