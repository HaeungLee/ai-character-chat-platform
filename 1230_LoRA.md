# 1230_LoRA.md

## 목표 (왜 LoRA인가)
- **프로덕트 관점**: 캐릭터별 말투/세계관/금지 규칙을 “프롬프트만으로” 유지하기 어려운 구간을 보완
- **비용/속도 관점**: 전체 파인튜닝(Full FT)보다 **학습 비용과 운영 비용이 낮고** 롤백이 쉬움
- **UX 관점**: 같은 캐릭터는 언제 접속해도 “일관된 톤/행동”을 보장 (RAG는 사실 기반, LoRA는 스타일/행동 기반)

## 전제 (권장 원칙)
- **Text first**: 텍스트 채팅 품질을 안정화한 뒤(프롬프트/메모리/RAG/채팅 SoT) LoRA로 “캐릭터성”을 강화
- **RAG vs LoRA 분리**
  - RAG: 사실/기억/세계관 데이터(업데이트가 잦음)
  - LoRA: 말투/행동 패턴/대사 리듬/선호(상대적으로 안정적)
- **안전/정책**: 수집 데이터에 PII/민감정보가 섞이면 학습 자체가 리스크가 됨 → 수집 단계에서 차단

---

## 파이프라인 개요 (End-to-End)
1) 데이터 수집(Opt-in) → 2) 정제/필터링(PII/품질) → 3) 데이터셋 버저닝
→ 4) 학습(LoRA/QLoRA) → 5) 평가(자동 게이트 + 소량 휴먼) → 6) 배포/서빙
→ 7) 모니터링/롤백

---

## 1) 데이터 수집 (Data Collection)

### 1.1 수집 소스
- **프로덕트 로그 기반(권장)**
  - 사용자/캐릭터 대화 로그(이미 존재하는 Chat/Message, Mongo 로그 등)
  - 캐릭터 설정: `systemPrompt`, lorebook, example dialogues
- **수동 작성 데이터(고품질)**
  - 캐릭터 작가/운영자가 만든 “정답 대화” (Few-shot 품질이 좋으면 학습 데이터로도 좋음)

### 1.2 Opt-in / 동의
- 학습 데이터는 기본적으로 **옵트인(명시적 동의)**이 안전
- “개인 데이터 제거/익명화/삭제 요청”의 대응 경로 필요

### 1.3 최소 수집 스키마 (권장)
- `character_id`, `dataset_source`, `timestamp`
- `messages`: [{role, content}]
- `style_tags`(선택): 캐릭터 말투/감정/행동 태그
- `safety_flags`(선택): NSFW, 폭력, 혐오, 자해 등

---

## 2) 정제/필터링 (Cleaning & Safety)

### 2.1 PII 제거(필수)
- 이메일/전화번호/주소/계좌/주민번호 등 정규식 + 룰 기반 제거
- 유저 닉네임/고유 ID는 마스킹

### 2.2 품질 필터(권장)
- 너무 짧은 턴/의미 없는 반복/스팸 제거
- “메타 발화” 제거(예: "나는 AI야", "시스템 프롬프트" 언급)
- 언어 정책(예: 한국어 전용) 강제 가능

### 2.3 캐릭터 누출 방지
- 서로 다른 캐릭터의 데이터가 섞이면 말투가 오염됨
- `character_id` 기준으로 **완전 분리** + 샘플링 검사

---

## 3) 데이터셋 포맷 (Training Format)

### 3.1 ChatML/OpenAI 스타일(권장)
학습 샘플은 “대화형”이 가장 관리가 쉬움.
- system: 캐릭터 핵심 규칙(짧게)
- user/assistant: 실제 대화 턴

### 3.2 샘플 구성 전략
- **스타일 튜닝(LoRA)**은 system을 짧게 두고 assistant 응답 품질을 학습시키는 편이 안정적
- lorebook/RAG 컨텍스트는 학습에 포함시키면 과적합 위험이 있음
  - 권장: LoRA는 톤/행동, RAG는 사실 주입으로 분리

---

## 4) 학습 (LoRA / QLoRA)

### 4.1 모델 선택
- 초기에는 “서빙 가능한” 베이스 모델을 선택 (운영 모델과 동일/유사 계열)
- 가능하면 **Instruct/Chat** 계열을 베이스로

### 4.2 학습 방식
- **LoRA**: 일반적, 안정적
- **QLoRA**: VRAM 절약(4bit), 비용 낮음 → 스타트에 유리

### 4.3 핵심 하이퍼파라미터(가이드)
- LoRA rank `r`: 8~32
- alpha: 16~64
- dropout: 0~0.1
- lr: 1e-4 ~ 2e-4(대략)
- epochs: 1~3(과적합 주의)

### 4.4 체크포인트/재현성
- dataset version, commit hash, base model revision, tokenizer revision
- seed 고정, train args 저장

---

## 5) 평가 (Evaluation)

### 5.1 자동 게이트(필수)
- **언어 준수**: 한국어만(또는 지정 언어)
- **메타 누출**: 시스템/개발자 프롬프트 언급 금지
- **반복/루프**: n-gram 반복률/길이 제한
- **정책 위반**: 금칙어/민감 컨텐츠 필터

### 5.2 캐릭터성 지표(권장)
- 톤/말투 키워드 체크
- 인물 설정(성격/말버릇) 일치율

### 5.3 소량 휴먼 평가
- 20~50개 프롬프트 셋으로 A/B
- “캐릭터성”은 자동 지표만으로는 한계가 있음

---

## 6) 배포/서빙 (Serving)

### 6.1 서빙 전략
- (A) **Adapter on-the-fly**: base + LoRA adapter 로딩
  - 장점: 롤백 쉬움, 캐릭터별 분리 쉬움
  - 단점: 인퍼런스 서버가 LoRA 스위칭을 지원해야 함
- (B) **Merge**: LoRA를 base에 merge해서 단일 모델로 배포
  - 장점: 서빙 단순
  - 단점: 롤백/다중 캐릭터 운영이 어려움

### 6.2 라우팅(캐릭터별)
- `characterId → (baseModel, adapterId)` 매핑 테이블
- 점진적 롤아웃: 일부 유저/세션만 LoRA 적용

---

## 7) 운영 (Monitoring & Rollback)

### 7.1 모니터링
- 응답 길이/지연/토큰 비용
- 금칙 위반율
- 반복/메타 누출율
- 유저 만족(리액션/리텐션)

### 7.2 롤백
- adapterId를 이전 버전으로 즉시 스위치
- 문제 샘플을 데이터셋에 “부정 예시”로 추가(다음 학습에 반영)

---

## 권장 실행 순서 (MVP → 확장)
1) 캐릭터 1개로 데이터 수집/정제 파이프라인부터 고정
2) QLoRA로 소규모 실험(빠르게) → 자동 게이트 통과
3) 2~3개 캐릭터로 확장(캐릭터 오염 방지 체크 강화)
4) 서빙 라우팅(캐릭터별 adapter) + 롤백 플로우 구축

---

## 결정해야 할 질문 (최소)
- LoRA를 **캐릭터 단위**로 할지, **카테고리 단위**로 할지?
- 운영 모델(서빙 베이스)은 무엇으로 고정할지?
- 데이터 옵트인 UX는 어디에 둘지? (설정/온보딩/팝업)
- NSFW 모드를 LoRA로 다룰지(리스크), 아니면 프롬프트/정책/필터로만 처리할지?
