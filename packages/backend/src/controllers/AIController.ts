// AI ì»¨íŠ¸ë¡¤ëŸ¬
import { Request, Response } from 'express'
import { AIService } from '../services/AIService'
import { logger } from '../utils/logger'
import { prisma } from '../config/database'
import { AuthenticatedRequest } from '../middleware/auth'
import { memoryIntegration } from '../services/memory'
import { LorebookEntry } from '../services/prompt/PromptAssembly'
import { buildCharacterChatSystemPrompt } from '../services/chat/CharacterChatPipeline'

export class AIController {
  private aiService: AIService

  constructor(aiService: AIService) {
    this.aiService = aiService
  }

  // ìºë¦­í„° ì±„íŒ… ì‘ë‹µ ìƒì„±
  generateCharacterResponse = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { characterId, message, conversationHistory, provider, model, nsfwMode, chatId } = req.body
      const userId = req.user?.id

      if (!characterId || !message) {
        return res.status(400).json({
          success: false,
          error: 'characterIdì™€ messageëŠ” í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // ìºë¦­í„° ì •ë³´ ì¡°íšŒ (ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ)
      const character = await this.getCharacterById(characterId)
      if (!character) {
        return res.status(404).json({
          success: false,
          error: 'ìºë¦­í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        })
      }

      const ragResult = await buildCharacterChatSystemPrompt({
        userId: userId || undefined,
        character: {
          id: character.id,
          name: character.name,
          systemPrompt: character.systemPrompt,
          lorebookEntries: character.lorebookEntries,
          exampleDialogues: character.exampleDialogues,
        },
        userMessage: message,
        outputLanguage: 'ko',
      })

      // AI ì‘ë‹µ ìƒì„±
      const response = await this.aiService.generateCharacterResponse(
        {
          ...character,
          systemPrompt: ragResult.systemPrompt,
        },
        message,
        conversationHistory || [],
        {
          provider,
          model,
          nsfwMode,
        }
      )

      // (ì„ íƒ) ë©”ëª¨ë¦¬ ì €ìž¥
      if (userId && typeof chatId === 'string' && chatId) {
        const nowIso = new Date().toISOString()
        const userMessageId = `msg_${Date.now()}_${Math.random().toString(36).slice(2, 10)}`
        const assistantMessageId = `msg_${Date.now()}_${Math.random().toString(36).slice(2, 10)}`

        void memoryIntegration
          .afterMessageProcess(
            {
              id: userMessageId,
              chatId,
              userId,
              characterId,
              role: 'user',
              content: message,
              metadata: { source: 'rest' },
            },
            character.name
          )
          .catch(() => {})

        void memoryIntegration
          .afterMessageProcess(
            {
              id: assistantMessageId,
              chatId,
              userId,
              characterId,
              role: 'assistant',
              content: response,
              tokens: Math.ceil(response.length / 3),
              metadata: { source: 'rest' },
            },
            character.name
          )
          .catch(() => {})
      }

      // ë¡œê·¸ ê¸°ë¡
      logger.info('AI ìºë¦­í„° ì‘ë‹µ ìƒì„± ì™„ë£Œ', {
        characterId,
        userId,
        messageLength: message.length,
        responseLength: response.length,
      })

      res.json({
        success: true,
        data: {
          response,
          character: {
            id: character.id,
            name: character.name,
          },
        },
      })
    } catch (error) {
      logger.error('AI ìºë¦­í„° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ì´ë¯¸ì§€ ìƒì„±
  generateImage = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const {
        prompt,
        model = 'replicate',
        style,
        aspectRatio = '1:1',
        negativePrompt
      } = req.body

      const userId = req.user?.id

      if (!prompt) {
        return res.status(400).json({
          success: false,
          error: 'í”„ë¡¬í”„íŠ¸ëŠ” í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // ì´ë¯¸ì§€ ìƒì„±
      const imageUrl = await this.aiService.generateImage(prompt, {
        model,
        style,
        aspectRatio,
        negativePrompt,
      })

      // ë¡œê·¸ ê¸°ë¡
      logger.info('AI ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ', {
        userId,
        model,
        promptLength: prompt.length,
      })

      res.json({
        success: true,
        data: {
          imageUrl,
          prompt,
          model,
          style,
          aspectRatio,
        },
      })
    } catch (error) {
      logger.error('AI ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ì¼ë°˜ ì±„íŒ… ì‘ë‹µ ìƒì„±
  generateChatResponse = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { messages, temperature, maxTokens } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      const response = await this.aiService.generateChatResponse(messages, {
        temperature,
        maxTokens,
      })

      logger.info('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì™„ë£Œ', {
        userId,
        messageCount: messages.length,
        responseLength: response.length,
      })

      res.json({
        success: true,
        data: {
          response,
          usage: {
            messageCount: messages.length,
          },
        },
      })
    } catch (error) {
      logger.error('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'ì±„íŒ… ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
  getServiceStatus = async (req: Request, res: Response) => {
    try {
      const status = this.aiService.getServiceStatus()
      const models = this.aiService.getAvailableModels()
      const credits = await this.aiService.getOpenRouterCredits()

      res.json({
        success: true,
        data: {
          status,
          models,
          openRouterCredits: credits,
          timestamp: new Date().toISOString(),
        },
      })
    } catch (error) {
      logger.error('AI ì„œë¹„ìŠ¤ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'ì„œë¹„ìŠ¤ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ðŸ†• í”„ë¡œë°”ì´ë” ì§€ì • ì±„íŒ… ì‘ë‹µ ìƒì„±
  generateChatWithProvider = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { 
        messages, 
        provider,      // 'openai' | 'openrouter'
        model,         // íŠ¹ì • ëª¨ë¸ ì§€ì •
        temperature, 
        maxTokens,
        nsfwMode       // ê²€ì—´ í•´ì œ ëª¨ë“œ
      } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // NSFW ëª¨ë“œëŠ” ì„±ì¸ ì¸ì¦ í™•ì¸ í•„ìš” (TODO: ì‹¤ì œ ì¸ì¦ ë¡œì§)
      if (nsfwMode) {
        // const isAdultVerified = await checkAdultVerification(userId)
        // if (!isAdultVerified) {
        //   return res.status(403).json({
        //     success: false,
        //     error: 'ì„±ì¸ ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.'
        //   })
        // }
        logger.warn('NSFW ëª¨ë“œ ìš”ì²­ - ì„±ì¸ ì¸ì¦ ë¯¸êµ¬í˜„', { userId })
      }

      const response = await this.aiService.generateChatResponse(messages, {
        provider,
        model,
        temperature,
        maxTokens,
        nsfwMode,
      })

      logger.info('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì™„ë£Œ', {
        userId,
        provider: provider || 'default',
        model: model || 'default',
        nsfwMode: !!nsfwMode,
        messageCount: messages.length,
        responseLength: response.length,
      })

      res.json({
        success: true,
        data: {
          response,
          provider: provider || this.aiService.getDefaultProvider(),
          model,
          usage: {
            messageCount: messages.length,
            estimatedTokens: Math.ceil(response.length / 4),
          },
        },
      })
    } catch (error) {
      logger.error('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: error instanceof Error ? error.message : 'ì±„íŒ… ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ðŸ†• í”„ë¡œë°”ì´ë” ì§€ì • ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
  generateChatStreamWithProvider = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { 
        messages, 
        provider,
        model,
        temperature, 
        maxTokens,
        nsfwMode
      } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // SSE í—¤ë” ì„¤ì •
      res.setHeader('Content-Type', 'text/event-stream')
      res.setHeader('Cache-Control', 'no-cache')
      res.setHeader('Connection', 'keep-alive')
      res.setHeader('X-Accel-Buffering', 'no')
      res.flushHeaders()

      const actualProvider = provider || this.aiService.getDefaultProvider()

      // ì‹œìž‘ ì´ë²¤íŠ¸
      res.write(`data: ${JSON.stringify({ 
        type: 'start', 
        provider: actualProvider,
        model: model || 'default',
        messageCount: messages.length 
      })}\n\n`)

      let fullResponse = ''

      try {
        const stream = this.aiService.generateChatResponseStream(messages, {
          provider,
          model,
          temperature,
          maxTokens,
          nsfwMode,
        })

        for await (const chunk of stream) {
          fullResponse += chunk
          res.write(`data: ${JSON.stringify({ type: 'chunk', content: chunk })}\n\n`)
        }

        res.write(`data: ${JSON.stringify({ 
          type: 'done', 
          fullResponse,
          provider: actualProvider,
          usage: {
            messageCount: messages.length,
            estimatedTokens: Math.ceil(fullResponse.length / 4)
          }
        })}\n\n`)

        logger.info('AI í”„ë¡œë°”ì´ë” ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ', {
          userId,
          provider: actualProvider,
          model,
          nsfwMode: !!nsfwMode,
          responseLength: fullResponse.length,
        })

      } catch (streamError) {
        res.write(`data: ${JSON.stringify({ 
          type: 'error', 
          error: streamError instanceof Error ? streamError.message : 'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' 
        })}\n\n`)
        logger.error('í”„ë¡œë°”ì´ë” ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜:', streamError)
      }

      res.write('data: [DONE]\n\n')
      res.end()

    } catch (error) {
      logger.error('AI í”„ë¡œë°”ì´ë” ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨:', error)
      
      if (!res.headersSent) {
        res.status(500).json({
          success: false,
          error: error instanceof Error ? error.message : 'ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        })
      } else {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        res.end()
      }
    }
  }

  // ðŸ†• ìºë¦­í„° ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (SSE)
  generateCharacterResponseStream = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { characterId, message, conversationHistory, provider, model, nsfwMode, chatId } = req.body
      const userId = req.user?.id

      if (!characterId || !message) {
        return res.status(400).json({
          success: false,
          error: 'characterIdì™€ messageëŠ” í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // ìºë¦­í„° ì •ë³´ ì¡°íšŒ
      const character = await this.getCharacterById(characterId)
      if (!character) {
        return res.status(404).json({
          success: false,
          error: 'ìºë¦­í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        })
      }

      // SSE í—¤ë” ì„¤ì •
      res.setHeader('Content-Type', 'text/event-stream')
      res.setHeader('Cache-Control', 'no-cache')
      res.setHeader('Connection', 'keep-alive')
      res.setHeader('X-Accel-Buffering', 'no') // Nginx ë²„í¼ë§ ë¹„í™œì„±í™”
      res.flushHeaders()

      // ì‹œìž‘ ì´ë²¤íŠ¸ ì „ì†¡
      res.write(`data: ${JSON.stringify({ type: 'start', characterId, characterName: character.name })}\n\n`)

      let fullResponse = ''

      try {
        const ragResult = await buildCharacterChatSystemPrompt({
          userId: userId || undefined,
          character: {
            id: character.id,
            name: character.name,
            systemPrompt: character.systemPrompt,
            lorebookEntries: character.lorebookEntries,
            exampleDialogues: character.exampleDialogues,
          },
          userMessage: message,
          outputLanguage: 'ko',
        })

        // (ì„ íƒ) ìœ ì € ë©”ì‹œì§€ ë©”ëª¨ë¦¬ ì €ìž¥
        if (userId && typeof chatId === 'string' && chatId) {
          void memoryIntegration
            .afterMessageProcess(
              {
                id: `msg_${Date.now()}_${Math.random().toString(36).slice(2, 10)}`,
                chatId,
                userId,
                characterId,
                role: 'user',
                content: message,
                metadata: { source: 'sse' },
              },
              character.name
            )
            .catch(() => {})
        }

        // ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        const stream = this.aiService.generateCharacterResponseStream(
          {
            ...character,
            systemPrompt: ragResult.systemPrompt,
          },
          message,
          conversationHistory || [],
          {
            provider,
            model,
            nsfwMode,
          }
        )

        for await (const chunk of stream) {
          fullResponse += chunk
          // ì²­í¬ ë°ì´í„° ì „ì†¡
          res.write(`data: ${JSON.stringify({ type: 'chunk', content: chunk })}\n\n`)
        }

        // ì™„ë£Œ ì´ë²¤íŠ¸ ì „ì†¡
        res.write(`data: ${JSON.stringify({ 
          type: 'done', 
          fullResponse,
          usage: {
            estimatedTokens: Math.ceil(fullResponse.length / 4)
          }
        })}\n\n`)

        // (ì„ íƒ) assistant ë©”ëª¨ë¦¬ ì €ìž¥
        if (userId && typeof chatId === 'string' && chatId) {
          void memoryIntegration
            .afterMessageProcess(
              {
                id: `msg_${Date.now()}_${Math.random().toString(36).slice(2, 10)}`,
                chatId,
                userId,
                characterId,
                role: 'assistant',
                content: fullResponse,
                tokens: Math.ceil(fullResponse.length / 3),
                metadata: { source: 'sse' },
              },
              character.name
            )
            .catch(() => {})
        }

        logger.info('AI ìºë¦­í„° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì™„ë£Œ', {
          characterId,
          userId,
          messageLength: message.length,
          responseLength: fullResponse.length,
        })

      } catch (streamError) {
        // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        logger.error('ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜:', streamError)
      }

      // ì—°ê²° ì¢…ë£Œ
      res.write('data: [DONE]\n\n')
      res.end()

    } catch (error) {
      logger.error('AI ìºë¦­í„° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      
      // ì•„ì§ í—¤ë”ê°€ ì „ì†¡ë˜ì§€ ì•Šì•˜ë‹¤ë©´ JSON ì‘ë‹µ
      if (!res.headersSent) {
        res.status(500).json({
          success: false,
          error: 'AI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        })
      } else {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        res.end()
      }
    }
  }

  // ðŸ†• ì¼ë°˜ ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (SSE)
  generateChatResponseStream = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { messages, temperature, maxTokens } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // SSE í—¤ë” ì„¤ì •
      res.setHeader('Content-Type', 'text/event-stream')
      res.setHeader('Cache-Control', 'no-cache')
      res.setHeader('Connection', 'keep-alive')
      res.setHeader('X-Accel-Buffering', 'no')
      res.flushHeaders()

      // ì‹œìž‘ ì´ë²¤íŠ¸ ì „ì†¡
      res.write(`data: ${JSON.stringify({ type: 'start', messageCount: messages.length })}\n\n`)

      let fullResponse = ''

      try {
        const stream = this.aiService.generateChatResponseStream(messages, {
          temperature,
          maxTokens,
        })

        for await (const chunk of stream) {
          fullResponse += chunk
          res.write(`data: ${JSON.stringify({ type: 'chunk', content: chunk })}\n\n`)
        }

        // ì™„ë£Œ ì´ë²¤íŠ¸
        res.write(`data: ${JSON.stringify({ 
          type: 'done', 
          fullResponse,
          usage: {
            messageCount: messages.length,
            estimatedTokens: Math.ceil(fullResponse.length / 4)
          }
        })}\n\n`)

        logger.info('AI ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì™„ë£Œ', {
          userId,
          messageCount: messages.length,
          responseLength: fullResponse.length,
        })

      } catch (streamError) {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        logger.error('ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜:', streamError)
      }

      res.write('data: [DONE]\n\n')
      res.end()

    } catch (error) {
      logger.error('AI ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      
      if (!res.headersSent) {
        res.status(500).json({
          success: false,
          error: 'ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        })
      } else {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        res.end()
      }
    }
  }

  // í—¬í¼ ë©”ì„œë“œ: ìºë¦­í„° ì •ë³´ ì¡°íšŒ
  private async getCharacterById(characterId: string) {
    const character = await prisma.character.findFirst({
      where: { id: characterId, isActive: true },
      include: {
        lorebookEntries: {
          where: { isActive: true },
          orderBy: { priority: 'desc' },
          select: { id: true, keys: true, content: true, priority: true },
        },
      },
    })

    if (!character) return null

    const lorebookEntries: LorebookEntry[] = (character.lorebookEntries || []).map((e) => ({
      id: e.id,
      keys: e.keys,
      content: e.content,
      priority: e.priority,
    }))

    return {
      id: character.id,
      name: character.name,
      personality: character.personality ?? '',
      systemPrompt: character.systemPrompt,
      temperature: 0.7,
      exampleDialogues: character.exampleDialogues,
      lorebookEntries,
    }
  }
}
