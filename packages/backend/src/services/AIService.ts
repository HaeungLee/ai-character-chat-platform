// í†µí•© AI ì„œë¹„ìŠ¤
import { OpenAIService, OpenAIConfig } from './ai/OpenAIService'
import { ReplicateService, ReplicateConfig } from './ai/ReplicateService'
import { StabilityAIService, StabilityConfig } from './ai/StabilityAIService'
import { logger } from '../utils/logger'

export interface AIServiceConfig {
  openai?: OpenAIConfig
  replicate?: ReplicateConfig
  stability?: StabilityConfig
}

export interface Character {
  id: string
  name: string
  personality: string
  systemPrompt: string
  temperature?: number
  avatar?: string
}

export interface ChatMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
  timestamp?: Date
}

export class AIService {
  private openai?: OpenAIService
  private replicate?: ReplicateService
  private stability?: StabilityAIService

  constructor(config: AIServiceConfig) {
    if (config.openai) {
      this.openai = new OpenAIService(config.openai)
    }
    if (config.replicate) {
      this.replicate = new ReplicateService(config.replicate)
    }
    if (config.stability) {
      this.stability = new StabilityAIService(config.stability)
    }
  }

  // ìºë¦­í„° ê¸°ë°˜ ì±„íŒ… ì‘ë‹µ ìƒì„±
  async generateCharacterResponse(
    character: Character,
    userMessage: string,
    conversationHistory: ChatMessage[] = []
  ): Promise<string> {
    if (!this.openai) {
      throw new Error('OpenAI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    }

    try {
      const characterPrompt = {
        name: character.name,
        personality: character.personality,
        systemPrompt: character.systemPrompt,
        temperature: character.temperature || 0.7,
      }

      const messages: ChatMessage[] = conversationHistory.map(msg => ({
        role: msg.role,
        content: msg.content,
      }))

      return await this.openai.generateCharacterResponse(
        characterPrompt,
        userMessage,
        messages
      )
    } catch (error) {
      logger.error('ìºë¦­í„° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)

      // Fallback ì‘ë‹µ
      return `${character.name}: ì£„ì†¡í•©ë‹ˆë‹¤. ì§€ê¸ˆì€ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`
    }
  }

  // ğŸ†• ìºë¦­í„° ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (íƒ€ìê¸° íš¨ê³¼)
  async *generateCharacterResponseStream(
    character: Character,
    userMessage: string,
    conversationHistory: ChatMessage[] = []
  ): AsyncGenerator<string, void, unknown> {
    if (!this.openai) {
      throw new Error('OpenAI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    }

    try {
      const characterPrompt = {
        name: character.name,
        personality: character.personality,
        systemPrompt: character.systemPrompt,
        temperature: character.temperature || 0.7,
      }

      const messages: ChatMessage[] = conversationHistory.map(msg => ({
        role: msg.role,
        content: msg.content,
      }))

      yield* this.openai.generateCharacterResponseStream(
        characterPrompt,
        userMessage,
        messages
      )
    } catch (error) {
      logger.error('ìºë¦­í„° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      throw error
    }
  }

  // ğŸ†• ì¼ë°˜ ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
  async *generateChatResponseStream(
    messages: ChatMessage[],
    options?: {
      model?: 'openai'
      temperature?: number
      maxTokens?: number
    }
  ): AsyncGenerator<string, void, unknown> {
    if (!this.openai) {
      throw new Error('OpenAI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    }

    yield* this.openai.generateChatResponseStream(messages, options)
  }

  // ì´ë¯¸ì§€ ìƒì„±
  async generateImage(
    prompt: string,
    options?: {
      model?: 'openai' | 'replicate' | 'stability'
      style?: string
      aspectRatio?: string
      negativePrompt?: string
    }
  ): Promise<string> {
    const model = options?.model || 'replicate'

    try {
      switch (model) {
        case 'openai':
          if (!this.openai) throw new Error('OpenAI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
          return await this.openai.generateImage(prompt, {
            size: this.mapAspectRatioToOpenAI(options?.aspectRatio),
            style: options?.style as any,
          })

        case 'replicate':
          if (!this.replicate) throw new Error('Replicate ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
          const dimensions = this.parseAspectRatio(options?.aspectRatio)
          return await this.replicate.generateImage(prompt, {
            width: dimensions.width,
            height: dimensions.height,
            negativePrompt: options?.negativePrompt,
          })

        case 'stability':
          if (!this.stability) throw new Error('Stability AI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
          const stabDimensions = this.parseAspectRatio(options?.aspectRatio)
          return await this.stability.generateImage(prompt, {
            width: stabDimensions.width,
            height: stabDimensions.height,
            negative_prompt: options?.negativePrompt,
            style_preset: options?.style,
          })

        default:
          throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: ${model}`)
      }
    } catch (error) {
      logger.error(`${model} ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨:`, error)

      // ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë¡œ í´ë°± ì‹œë„
      if (model !== 'replicate' && this.replicate) {
        logger.info('Replicateë¡œ í´ë°± ì‹œë„')
        try {
          const dimensions = this.parseAspectRatio(options?.aspectRatio)
          return await this.replicate.generateImage(prompt, {
            width: dimensions.width,
            height: dimensions.height,
            negativePrompt: options?.negativePrompt,
          })
        } catch (fallbackError) {
          logger.error('í´ë°±ë„ ì‹¤íŒ¨:', fallbackError)
        }
      }

      throw new Error('ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.')
    }
  }

  // ì¼ë°˜ ì±„íŒ… ì‘ë‹µ ìƒì„±
  async generateChatResponse(
    messages: ChatMessage[],
    options?: {
      model?: 'openai'
      temperature?: number
      maxTokens?: number
    }
  ): Promise<string> {
    if (!this.openai) {
      throw new Error('OpenAI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    }

    return await this.openai.generateChatResponse(messages, options)
  }

  // ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
  getServiceStatus(): {
    openai: boolean
    replicate: boolean
    stability: boolean
  } {
    return {
      openai: !!this.openai,
      replicate: !!this.replicate,
      stability: !!this.stability,
    }
  }

  // ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
  getAvailableModels(): {
    chat: string[]
    image: string[]
  } {
    const status = this.getServiceStatus()

    return {
      chat: status.openai ? ['gpt-4', 'gpt-3.5-turbo'] : [],
      image: [
        ...(status.openai ? ['openai/dall-e-3'] : []),
        ...(status.replicate ? ['replicate/sdxl', 'replicate/sdxl-turbo'] : []),
        ...(status.stability ? ['stability/sdxl', 'stability/core'] : []),
      ],
    }
  }

  // í—¬í¼ í•¨ìˆ˜ë“¤
  private mapAspectRatioToOpenAI(aspectRatio?: string): any {
    const ratioMap: Record<string, string> = {
      '1:1': '1024x1024',
      '16:9': '1792x1024',
      '9:16': '1024x1792',
      '4:3': '1024x768',
      '3:4': '768x1024',
    }
    return ratioMap[aspectRatio || '1:1'] || '1024x1024'
  }

  private parseAspectRatio(aspectRatio?: string): { width: number; height: number } {
    if (!aspectRatio) return { width: 1024, height: 1024 }

    const [widthStr, heightStr] = aspectRatio.split(':')
    const width = parseInt(widthStr)
    const height = parseInt(heightStr)

    if (isNaN(width) || isNaN(height)) return { width: 1024, height: 1024 }

    // ìµœëŒ€ í¬ê¸° ì œí•œ
    const maxSize = 1024
    let actualWidth = width
    let actualHeight = height

    if (width > height) {
      actualWidth = Math.min(width, maxSize)
      actualHeight = Math.round((height * actualWidth) / width)
    } else {
      actualHeight = Math.min(height, maxSize)
      actualWidth = Math.round((width * actualHeight) / height)
    }

    return { width: actualWidth, height: actualHeight }
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í•¨ìˆ˜
export function createAIService(config: AIServiceConfig): AIService {
  return new AIService(config)
}

// í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ìƒì„±
export function createAIServiceFromEnv(): AIService {
  const config: AIServiceConfig = {}

  if (process.env.OPENAI_API_KEY) {
    config.openai = {
      apiKey: process.env.OPENAI_API_KEY,
      organization: process.env.OPENAI_ORGANIZATION_ID,
      model: 'gpt-4',
      temperature: 0.7,
      maxTokens: 1000,
    }
  }

  if (process.env.REPLICATE_API_TOKEN) {
    config.replicate = {
      apiToken: process.env.REPLICATE_API_TOKEN,
    }
  }

  if (process.env.STABILITY_API_KEY) {
    config.stability = {
      apiKey: process.env.STABILITY_API_KEY,
    }
  }

  return new AIService(config)
}
