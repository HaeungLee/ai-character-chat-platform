// AI ì»¨íŠ¸ë¡¤ëŸ¬
import { Request, Response } from 'express'
import { AIService } from '../services/AIService'
import { logger } from '../utils/logger'
import { prisma } from '../config/database'
import { AuthenticatedRequest } from '../middleware/auth'
import { assembleSystemPrompt, LorebookEntry } from '../services/prompt/PromptAssembly'
import { runCharacterChatTurnRest, runCharacterChatTurnSse } from '../services/chat/CharacterChatTurnPipeline'
import { memoryIntegration } from '../services/memory'
import { resolveOrCreateChatId } from '../services/chat/ChatSessionService'

export class AIController {
  private aiService: AIService

  constructor(aiService: AIService) {
    this.aiService = aiService
  }

  // ìºë¦­í„° ì±„íŒ… ì‘ë‹µ ìƒì„±
  generateCharacterResponse = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { characterId, message, conversationHistory, provider, model, nsfwMode, chatId } = req.body
      const userId = req.user?.id

      if (!characterId || !message) {
        return res.status(400).json({
          success: false,
          error: 'characterIdì™€ messageëŠ” í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // ìºë¦­í„° ì •ë³´ ì¡°íšŒ (ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ)
      const character = await this.getCharacterById(characterId)
      if (!character) {
        return res.status(404).json({
          success: false,
          error: 'ìºë¦­í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        })
      }

      const result = await runCharacterChatTurnRest({
        aiService: this.aiService,
        userId: userId || undefined,
        chatId,
        character: {
          id: character.id,
          name: character.name,
          systemPrompt: character.systemPrompt,
          personality: character.personality,
          temperature: character.temperature,
          lorebookEntries: character.lorebookEntries,
          exampleDialogues: character.exampleDialogues,
        },
        userMessage: message,
        conversationHistory: conversationHistory || [],
        aiOptions: {
          provider,
          model,
          nsfwMode,
        },
        outputLanguage: 'ko',
      })

      // ë¡œê·¸ ê¸°ë¡
      logger.info('AI ìºë¦­í„° ì‘ë‹µ ìƒì„± ì™„ë£Œ', {
        characterId,
        userId,
        messageLength: message.length,
        responseLength: result.response.length,
      })

      res.json({
        success: true,
        data: {
          response: result.response,
          character: {
            id: character.id,
            name: character.name,
          },
        },
      })
    } catch (error) {
      logger.error('AI ìºë¦­í„° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ðŸ†• ìºë¦­í„° ì±„íŒ… í”„ë¡¬í”„íŠ¸/ì»¨í…ìŠ¤íŠ¸ í”„ë¦¬ë·° (LLM í˜¸ì¶œ ì—†ìŒ)
  previewCharacterChatPrompt = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const {
        characterId,
        message,
        includeRag = true,
        outputLanguage = 'ko',
        maxLorebookEntries,
        maxExamplesChars,
        includeHardRules,
      } = req.body as {
        characterId?: string
        message?: string
        includeRag?: boolean
        outputLanguage?: 'ko' | 'en'
        maxLorebookEntries?: number
        maxExamplesChars?: number
        includeHardRules?: boolean
      }

      const userId = req.user?.id

      if (!characterId || typeof characterId !== 'string') {
        return res.status(400).json({ success: false, error: 'characterIdëŠ” í•„ìˆ˜ìž…ë‹ˆë‹¤.' })
      }

      if (!message || typeof message !== 'string') {
        return res.status(400).json({ success: false, error: 'messageëŠ” í•„ìˆ˜ìž…ë‹ˆë‹¤.' })
      }

      const character = await this.getCharacterById(characterId)
      if (!character) {
        return res.status(404).json({ success: false, error: 'ìºë¦­í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' })
      }

      const assembled = assembleSystemPrompt({
        baseSystemPrompt: character.systemPrompt,
        userMessage: message,
        lorebookEntries: character.lorebookEntries,
        exampleDialoguesJson: character.exampleDialogues,
        options: {
          outputLanguage,
          ...(typeof maxLorebookEntries === 'number' ? { maxLorebookEntries } : {}),
          ...(typeof maxExamplesChars === 'number' ? { maxExamplesChars } : {}),
          ...(typeof includeHardRules === 'boolean' ? { includeHardRules } : {}),
        },
      })

      let finalSystemPrompt = assembled.assembledSystemPrompt
      let ragContext: { formattedContext: string; totalTokens: number } = { formattedContext: '', totalTokens: 0 }
      let ragError: string | null = null

      if (includeRag && userId) {
        try {
          const ragResult = await memoryIntegration.beforeMessageProcess(
            userId,
            character.id,
            character.name,
            message,
            assembled.assembledSystemPrompt
          )
          finalSystemPrompt = ragResult.systemPrompt
          ragContext = ragResult.ragContext
        } catch (e) {
          ragError = e instanceof Error ? e.message : 'RAG ì£¼ìž… ì‹¤íŒ¨'
        }
      }

      return res.json({
        success: true,
        data: {
          character: { id: character.id, name: character.name },
          input: {
            message,
            includeRag: !!includeRag,
            outputLanguage,
            maxLorebookEntries: typeof maxLorebookEntries === 'number' ? maxLorebookEntries : null,
            maxExamplesChars: typeof maxExamplesChars === 'number' ? maxExamplesChars : null,
            includeHardRules: typeof includeHardRules === 'boolean' ? includeHardRules : null,
          },
          assembly: {
            usedLorebookEntries: assembled.usedLorebookEntries,
            usedLorebookEntryIds: assembled.usedLorebookEntries.map((e) => e.id),
            usedExamplesCount: assembled.usedExamples.length,
          },
          prompts: {
            assembledSystemPrompt: assembled.assembledSystemPrompt,
            finalSystemPrompt,
          },
          rag: {
            totalTokens: ragContext.totalTokens,
            formattedContext: ragContext.formattedContext,
            error: ragError,
          },
          note: 'This endpoint does not call the LLM. Use /api/ai/chat or /api/ai/chat/stream for actual responses.',
        },
      })
    } catch (error) {
      logger.error('í”„ë¡¬í”„íŠ¸ í”„ë¦¬ë·° ìƒì„± ì‹¤íŒ¨:', error)
      return res.status(500).json({ success: false, error: 'í”„ë¡¬í”„íŠ¸ í”„ë¦¬ë·° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })
    }
  }

  // ì´ë¯¸ì§€ ìƒì„±
  generateImage = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const {
        prompt,
        model = 'replicate',
        style,
        aspectRatio = '1:1',
        negativePrompt
      } = req.body

      const userId = req.user?.id

      if (!prompt) {
        return res.status(400).json({
          success: false,
          error: 'í”„ë¡¬í”„íŠ¸ëŠ” í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // ì´ë¯¸ì§€ ìƒì„±
      const imageUrl = await this.aiService.generateImage(prompt, {
        model,
        style,
        aspectRatio,
        negativePrompt,
      })

      // ë¡œê·¸ ê¸°ë¡
      logger.info('AI ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ', {
        userId,
        model,
        promptLength: prompt.length,
      })

      res.json({
        success: true,
        data: {
          imageUrl,
          prompt,
          model,
          style,
          aspectRatio,
        },
      })
    } catch (error) {
      logger.error('AI ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ì¼ë°˜ ì±„íŒ… ì‘ë‹µ ìƒì„±
  generateChatResponse = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { messages, temperature, maxTokens } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      const response = await this.aiService.generateChatResponse(messages, {
        temperature,
        maxTokens,
      })

      logger.info('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì™„ë£Œ', {
        userId,
        messageCount: messages.length,
        responseLength: response.length,
      })

      res.json({
        success: true,
        data: {
          response,
          usage: {
            messageCount: messages.length,
          },
        },
      })
    } catch (error) {
      logger.error('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'ì±„íŒ… ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
  getServiceStatus = async (req: Request, res: Response) => {
    try {
      const status = this.aiService.getServiceStatus()
      const models = this.aiService.getAvailableModels()
      const credits = await this.aiService.getOpenRouterCredits()

      res.json({
        success: true,
        data: {
          status,
          models,
          openRouterCredits: credits,
          timestamp: new Date().toISOString(),
        },
      })
    } catch (error) {
      logger.error('AI ì„œë¹„ìŠ¤ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'ì„œë¹„ìŠ¤ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ðŸ†• í”„ë¡œë°”ì´ë” ì§€ì • ì±„íŒ… ì‘ë‹µ ìƒì„±
  generateChatWithProvider = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { 
        messages, 
        provider,      // 'openai' | 'openrouter'
        model,         // íŠ¹ì • ëª¨ë¸ ì§€ì •
        temperature, 
        maxTokens,
        nsfwMode       // ê²€ì—´ í•´ì œ ëª¨ë“œ
      } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // NSFW ëª¨ë“œëŠ” ì„±ì¸ ì¸ì¦ í™•ì¸ í•„ìš” (TODO: ì‹¤ì œ ì¸ì¦ ë¡œì§)
      if (nsfwMode) {
        // const isAdultVerified = await checkAdultVerification(userId)
        // if (!isAdultVerified) {
        //   return res.status(403).json({
        //     success: false,
        //     error: 'ì„±ì¸ ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.'
        //   })
        // }
        logger.warn('NSFW ëª¨ë“œ ìš”ì²­ - ì„±ì¸ ì¸ì¦ ë¯¸êµ¬í˜„', { userId })
      }

      const response = await this.aiService.generateChatResponse(messages, {
        provider,
        model,
        temperature,
        maxTokens,
        nsfwMode,
      })

      logger.info('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì™„ë£Œ', {
        userId,
        provider: provider || 'default',
        model: model || 'default',
        nsfwMode: !!nsfwMode,
        messageCount: messages.length,
        responseLength: response.length,
      })

      res.json({
        success: true,
        data: {
          response,
          provider: provider || this.aiService.getDefaultProvider(),
          model,
          usage: {
            messageCount: messages.length,
            estimatedTokens: Math.ceil(response.length / 4),
          },
        },
      })
    } catch (error) {
      logger.error('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: error instanceof Error ? error.message : 'ì±„íŒ… ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ðŸ†• í”„ë¡œë°”ì´ë” ì§€ì • ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
  generateChatStreamWithProvider = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { 
        messages, 
        provider,
        model,
        temperature, 
        maxTokens,
        nsfwMode
      } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // SSE í—¤ë” ì„¤ì •
      res.setHeader('Content-Type', 'text/event-stream')
      res.setHeader('Cache-Control', 'no-cache')
      res.setHeader('Connection', 'keep-alive')
      res.setHeader('X-Accel-Buffering', 'no')
      res.flushHeaders()

      const actualProvider = provider || this.aiService.getDefaultProvider()

      // ì‹œìž‘ ì´ë²¤íŠ¸
      res.write(`data: ${JSON.stringify({ 
        type: 'start', 
        provider: actualProvider,
        model: model || 'default',
        messageCount: messages.length 
      })}\n\n`)

      let fullResponse = ''

      try {
        const stream = this.aiService.generateChatResponseStream(messages, {
          provider,
          model,
          temperature,
          maxTokens,
          nsfwMode,
        })

        for await (const chunk of stream) {
          fullResponse += chunk
          res.write(`data: ${JSON.stringify({ type: 'chunk', content: chunk })}\n\n`)
        }

        res.write(`data: ${JSON.stringify({ 
          type: 'done', 
          fullResponse,
          provider: actualProvider,
          usage: {
            messageCount: messages.length,
            estimatedTokens: Math.ceil(fullResponse.length / 4)
          }
        })}\n\n`)

        logger.info('AI í”„ë¡œë°”ì´ë” ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ', {
          userId,
          provider: actualProvider,
          model,
          nsfwMode: !!nsfwMode,
          responseLength: fullResponse.length,
        })

      } catch (streamError) {
        res.write(`data: ${JSON.stringify({ 
          type: 'error', 
          error: streamError instanceof Error ? streamError.message : 'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' 
        })}\n\n`)
        logger.error('í”„ë¡œë°”ì´ë” ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜:', streamError)
      }

      res.write('data: [DONE]\n\n')
      res.end()

    } catch (error) {
      logger.error('AI í”„ë¡œë°”ì´ë” ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨:', error)
      
      if (!res.headersSent) {
        res.status(500).json({
          success: false,
          error: error instanceof Error ? error.message : 'ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        })
      } else {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        res.end()
      }
    }
  }

  // ðŸ†• ìºë¦­í„° ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (SSE)
  generateCharacterResponseStream = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { characterId, message, conversationHistory, provider, model, nsfwMode, chatId } = req.body
      const userId = req.user?.id

      if (!characterId || !message) {
        return res.status(400).json({
          success: false,
          error: 'characterIdì™€ messageëŠ” í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // ìºë¦­í„° ì •ë³´ ì¡°íšŒ
      const character = await this.getCharacterById(characterId)
      if (!character) {
        return res.status(404).json({
          success: false,
          error: 'ìºë¦­í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        })
      }

      // SSE í—¤ë” ì„¤ì •
      res.setHeader('Content-Type', 'text/event-stream')
      res.setHeader('Cache-Control', 'no-cache')
      res.setHeader('Connection', 'keep-alive')
      res.setHeader('X-Accel-Buffering', 'no') // Nginx ë²„í¼ë§ ë¹„í™œì„±í™”
      res.flushHeaders()

      const { chatId: resolvedChatId } = await resolveOrCreateChatId({
        prisma,
        userId: userId || undefined,
        characterId,
        chatId,
      })

      // ì‹œìž‘ ì´ë²¤íŠ¸ ì „ì†¡
      res.write(
        `data: ${JSON.stringify({
          type: 'start',
          characterId,
          characterName: character.name,
          ...(resolvedChatId ? { chatId: resolvedChatId } : {}),
        })}\n\n`
      )

      try {
        const stream = runCharacterChatTurnSse({
          aiService: this.aiService,
          userId: userId || undefined,
          chatId: resolvedChatId,
          character: {
            id: character.id,
            name: character.name,
            systemPrompt: character.systemPrompt,
            personality: character.personality,
            temperature: character.temperature,
            lorebookEntries: character.lorebookEntries,
            exampleDialogues: character.exampleDialogues,
          },
          userMessage: message,
          conversationHistory: conversationHistory || [],
          aiOptions: {
            provider,
            model,
            nsfwMode,
          },
          outputLanguage: 'ko',
        })

        let fullResponse = ''
        for await (const evt of stream) {
          if (evt.type === 'chunk') {
            fullResponse += evt.content
            res.write(`data: ${JSON.stringify({ type: 'chunk', content: evt.content })}\n\n`)
          } else if (evt.type === 'done') {
            fullResponse = evt.fullResponse
            res.write(`data: ${JSON.stringify({ 
              type: 'done', 
              fullResponse,
              usage: evt.usage,
            })}\n\n`)
          }
        }

        logger.info('AI ìºë¦­í„° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì™„ë£Œ', {
          characterId,
          userId,
          messageLength: message.length,
          responseLength: fullResponse.length,
        })

      } catch (streamError) {
        // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        logger.error('ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜:', streamError)
      }

      // ì—°ê²° ì¢…ë£Œ
      res.write('data: [DONE]\n\n')
      res.end()

    } catch (error) {
      logger.error('AI ìºë¦­í„° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      
      // ì•„ì§ í—¤ë”ê°€ ì „ì†¡ë˜ì§€ ì•Šì•˜ë‹¤ë©´ JSON ì‘ë‹µ
      if (!res.headersSent) {
        res.status(500).json({
          success: false,
          error: 'AI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        })
      } else {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        res.end()
      }
    }
  }

  // ðŸ†• ì¼ë°˜ ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (SSE)
  generateChatResponseStream = async (req: AuthenticatedRequest, res: Response) => {
    try {
      const { messages, temperature, maxTokens } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ìž…ë‹ˆë‹¤.'
        })
      }

      // SSE í—¤ë” ì„¤ì •
      res.setHeader('Content-Type', 'text/event-stream')
      res.setHeader('Cache-Control', 'no-cache')
      res.setHeader('Connection', 'keep-alive')
      res.setHeader('X-Accel-Buffering', 'no')
      res.flushHeaders()

      // ì‹œìž‘ ì´ë²¤íŠ¸ ì „ì†¡
      res.write(`data: ${JSON.stringify({ type: 'start', messageCount: messages.length })}\n\n`)

      let fullResponse = ''

      try {
        const stream = this.aiService.generateChatResponseStream(messages, {
          temperature,
          maxTokens,
        })

        for await (const chunk of stream) {
          fullResponse += chunk
          res.write(`data: ${JSON.stringify({ type: 'chunk', content: chunk })}\n\n`)
        }

        // ì™„ë£Œ ì´ë²¤íŠ¸
        res.write(`data: ${JSON.stringify({ 
          type: 'done', 
          fullResponse,
          usage: {
            messageCount: messages.length,
            estimatedTokens: Math.ceil(fullResponse.length / 4)
          }
        })}\n\n`)

        logger.info('AI ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì™„ë£Œ', {
          userId,
          messageCount: messages.length,
          responseLength: fullResponse.length,
        })

      } catch (streamError) {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        logger.error('ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜:', streamError)
      }

      res.write('data: [DONE]\n\n')
      res.end()

    } catch (error) {
      logger.error('AI ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      
      if (!res.headersSent) {
        res.status(500).json({
          success: false,
          error: 'ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        })
      } else {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        res.end()
      }
    }
  }

  // í—¬í¼ ë©”ì„œë“œ: ìºë¦­í„° ì •ë³´ ì¡°íšŒ
  private async getCharacterById(characterId: string) {
    const character = await prisma.character.findFirst({
      where: { id: characterId, isActive: true },
      include: {
        lorebookEntries: {
          where: { isActive: true },
          orderBy: { priority: 'desc' },
          select: { id: true, keys: true, content: true, priority: true },
        },
      },
    })

    if (!character) return null

    const lorebookEntries: LorebookEntry[] = (character.lorebookEntries || []).map((e) => ({
      id: e.id,
      keys: e.keys,
      content: e.content,
      priority: e.priority,
    }))

    return {
      id: character.id,
      name: character.name,
      personality: character.personality ?? '',
      systemPrompt: character.systemPrompt,
      temperature: 0.7,
      exampleDialogues: character.exampleDialogues,
      lorebookEntries,
    }
  }
}
