// AI ì»¨íŠ¸ë¡¤ëŸ¬
import { Request, Response } from 'express'
import { AIService } from '../services/AIService'
import { logger } from '../utils/logger'

export class AIController {
  private aiService: AIService

  constructor(aiService: AIService) {
    this.aiService = aiService
  }

  // ìºë¦­í„° ì±„íŒ… ì‘ë‹µ ìƒì„±
  generateCharacterResponse = async (req: Request, res: Response) => {
    try {
      const { characterId, message, conversationHistory } = req.body
      const userId = req.user?.id

      if (!characterId || !message) {
        return res.status(400).json({
          success: false,
          error: 'characterIdì™€ messageëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.'
        })
      }

      // ìºë¦­í„° ì •ë³´ ì¡°íšŒ (ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ)
      const character = await this.getCharacterById(characterId)
      if (!character) {
        return res.status(404).json({
          success: false,
          error: 'ìºë¦­í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        })
      }

      // AI ì‘ë‹µ ìƒì„±
      const response = await this.aiService.generateCharacterResponse(
        character,
        message,
        conversationHistory || []
      )

      // ë¡œê·¸ ê¸°ë¡
      logger.info('AI ìºë¦­í„° ì‘ë‹µ ìƒì„± ì™„ë£Œ', {
        characterId,
        userId,
        messageLength: message.length,
        responseLength: response.length,
      })

      res.json({
        success: true,
        data: {
          response,
          character: {
            id: character.id,
            name: character.name,
          },
        },
      })
    } catch (error) {
      logger.error('AI ìºë¦­í„° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ì´ë¯¸ì§€ ìƒì„±
  generateImage = async (req: Request, res: Response) => {
    try {
      const {
        prompt,
        model = 'replicate',
        style,
        aspectRatio = '1:1',
        negativePrompt
      } = req.body

      const userId = req.user?.id

      if (!prompt) {
        return res.status(400).json({
          success: false,
          error: 'í”„ë¡¬í”„íŠ¸ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.'
        })
      }

      // ì´ë¯¸ì§€ ìƒì„±
      const imageUrl = await this.aiService.generateImage(prompt, {
        model,
        style,
        aspectRatio,
        negativePrompt,
      })

      // ë¡œê·¸ ê¸°ë¡
      logger.info('AI ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ', {
        userId,
        model,
        promptLength: prompt.length,
      })

      res.json({
        success: true,
        data: {
          imageUrl,
          prompt,
          model,
          style,
          aspectRatio,
        },
      })
    } catch (error) {
      logger.error('AI ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ì¼ë°˜ ì±„íŒ… ì‘ë‹µ ìƒì„±
  generateChatResponse = async (req: Request, res: Response) => {
    try {
      const { messages, temperature, maxTokens } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.'
        })
      }

      const response = await this.aiService.generateChatResponse(messages, {
        temperature,
        maxTokens,
      })

      logger.info('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì™„ë£Œ', {
        userId,
        messageCount: messages.length,
        responseLength: response.length,
      })

      res.json({
        success: true,
        data: {
          response,
          usage: {
            messageCount: messages.length,
          },
        },
      })
    } catch (error) {
      logger.error('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'ì±„íŒ… ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
  getServiceStatus = async (req: Request, res: Response) => {
    try {
      const status = this.aiService.getServiceStatus()
      const models = this.aiService.getAvailableModels()
      const credits = await this.aiService.getOpenRouterCredits()

      res.json({
        success: true,
        data: {
          status,
          models,
          openRouterCredits: credits,
          timestamp: new Date().toISOString(),
        },
      })
    } catch (error) {
      logger.error('AI ì„œë¹„ìŠ¤ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: 'ì„œë¹„ìŠ¤ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ğŸ†• í”„ë¡œë°”ì´ë” ì§€ì • ì±„íŒ… ì‘ë‹µ ìƒì„±
  generateChatWithProvider = async (req: Request, res: Response) => {
    try {
      const { 
        messages, 
        provider,      // 'openai' | 'openrouter'
        model,         // íŠ¹ì • ëª¨ë¸ ì§€ì •
        temperature, 
        maxTokens,
        nsfwMode       // ê²€ì—´ í•´ì œ ëª¨ë“œ
      } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.'
        })
      }

      // NSFW ëª¨ë“œëŠ” ì„±ì¸ ì¸ì¦ í™•ì¸ í•„ìš” (TODO: ì‹¤ì œ ì¸ì¦ ë¡œì§)
      if (nsfwMode) {
        // const isAdultVerified = await checkAdultVerification(userId)
        // if (!isAdultVerified) {
        //   return res.status(403).json({
        //     success: false,
        //     error: 'ì„±ì¸ ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.'
        //   })
        // }
        logger.warn('NSFW ëª¨ë“œ ìš”ì²­ - ì„±ì¸ ì¸ì¦ ë¯¸êµ¬í˜„', { userId })
      }

      const response = await this.aiService.generateChatResponse(messages, {
        provider,
        model,
        temperature,
        maxTokens,
        nsfwMode,
      })

      logger.info('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì™„ë£Œ', {
        userId,
        provider: provider || 'default',
        model: model || 'default',
        nsfwMode: !!nsfwMode,
        messageCount: messages.length,
        responseLength: response.length,
      })

      res.json({
        success: true,
        data: {
          response,
          provider: provider || this.aiService.getDefaultProvider(),
          model,
          usage: {
            messageCount: messages.length,
            estimatedTokens: Math.ceil(response.length / 4),
          },
        },
      })
    } catch (error) {
      logger.error('AI ì±„íŒ… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        error: error instanceof Error ? error.message : 'ì±„íŒ… ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      })
    }
  }

  // ğŸ†• í”„ë¡œë°”ì´ë” ì§€ì • ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
  generateChatStreamWithProvider = async (req: Request, res: Response) => {
    try {
      const { 
        messages, 
        provider,
        model,
        temperature, 
        maxTokens,
        nsfwMode
      } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.'
        })
      }

      // SSE í—¤ë” ì„¤ì •
      res.setHeader('Content-Type', 'text/event-stream')
      res.setHeader('Cache-Control', 'no-cache')
      res.setHeader('Connection', 'keep-alive')
      res.setHeader('X-Accel-Buffering', 'no')
      res.flushHeaders()

      const actualProvider = provider || this.aiService.getDefaultProvider()

      // ì‹œì‘ ì´ë²¤íŠ¸
      res.write(`data: ${JSON.stringify({ 
        type: 'start', 
        provider: actualProvider,
        model: model || 'default',
        messageCount: messages.length 
      })}\n\n`)

      let fullResponse = ''

      try {
        const stream = this.aiService.generateChatResponseStream(messages, {
          provider,
          model,
          temperature,
          maxTokens,
          nsfwMode,
        })

        for await (const chunk of stream) {
          fullResponse += chunk
          res.write(`data: ${JSON.stringify({ type: 'chunk', content: chunk })}\n\n`)
        }

        res.write(`data: ${JSON.stringify({ 
          type: 'done', 
          fullResponse,
          provider: actualProvider,
          usage: {
            messageCount: messages.length,
            estimatedTokens: Math.ceil(fullResponse.length / 4)
          }
        })}\n\n`)

        logger.info('AI í”„ë¡œë°”ì´ë” ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ', {
          userId,
          provider: actualProvider,
          model,
          nsfwMode: !!nsfwMode,
          responseLength: fullResponse.length,
        })

      } catch (streamError) {
        res.write(`data: ${JSON.stringify({ 
          type: 'error', 
          error: streamError instanceof Error ? streamError.message : 'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' 
        })}\n\n`)
        logger.error('í”„ë¡œë°”ì´ë” ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜:', streamError)
      }

      res.write('data: [DONE]\n\n')
      res.end()

    } catch (error) {
      logger.error('AI í”„ë¡œë°”ì´ë” ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨:', error)
      
      if (!res.headersSent) {
        res.status(500).json({
          success: false,
          error: error instanceof Error ? error.message : 'ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        })
      } else {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        res.end()
      }
    }
  }

  // ğŸ†• ìºë¦­í„° ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (SSE)
  generateCharacterResponseStream = async (req: Request, res: Response) => {
    try {
      const { characterId, message, conversationHistory } = req.body
      const userId = req.user?.id

      if (!characterId || !message) {
        return res.status(400).json({
          success: false,
          error: 'characterIdì™€ messageëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.'
        })
      }

      // ìºë¦­í„° ì •ë³´ ì¡°íšŒ
      const character = await this.getCharacterById(characterId)
      if (!character) {
        return res.status(404).json({
          success: false,
          error: 'ìºë¦­í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        })
      }

      // SSE í—¤ë” ì„¤ì •
      res.setHeader('Content-Type', 'text/event-stream')
      res.setHeader('Cache-Control', 'no-cache')
      res.setHeader('Connection', 'keep-alive')
      res.setHeader('X-Accel-Buffering', 'no') // Nginx ë²„í¼ë§ ë¹„í™œì„±í™”
      res.flushHeaders()

      // ì‹œì‘ ì´ë²¤íŠ¸ ì „ì†¡
      res.write(`data: ${JSON.stringify({ type: 'start', characterId, characterName: character.name })}\n\n`)

      let fullResponse = ''

      try {
        // ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        const stream = this.aiService.generateCharacterResponseStream(
          character,
          message,
          conversationHistory || []
        )

        for await (const chunk of stream) {
          fullResponse += chunk
          // ì²­í¬ ë°ì´í„° ì „ì†¡
          res.write(`data: ${JSON.stringify({ type: 'chunk', content: chunk })}\n\n`)
        }

        // ì™„ë£Œ ì´ë²¤íŠ¸ ì „ì†¡
        res.write(`data: ${JSON.stringify({ 
          type: 'done', 
          fullResponse,
          usage: {
            estimatedTokens: Math.ceil(fullResponse.length / 4)
          }
        })}\n\n`)

        logger.info('AI ìºë¦­í„° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì™„ë£Œ', {
          characterId,
          userId,
          messageLength: message.length,
          responseLength: fullResponse.length,
        })

      } catch (streamError) {
        // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        logger.error('ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜:', streamError)
      }

      // ì—°ê²° ì¢…ë£Œ
      res.write('data: [DONE]\n\n')
      res.end()

    } catch (error) {
      logger.error('AI ìºë¦­í„° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      
      // ì•„ì§ í—¤ë”ê°€ ì „ì†¡ë˜ì§€ ì•Šì•˜ë‹¤ë©´ JSON ì‘ë‹µ
      if (!res.headersSent) {
        res.status(500).json({
          success: false,
          error: 'AI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        })
      } else {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        res.end()
      }
    }
  }

  // ğŸ†• ì¼ë°˜ ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (SSE)
  generateChatResponseStream = async (req: Request, res: Response) => {
    try {
      const { messages, temperature, maxTokens } = req.body
      const userId = req.user?.id

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({
          success: false,
          error: 'messages ë°°ì—´ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.'
        })
      }

      // SSE í—¤ë” ì„¤ì •
      res.setHeader('Content-Type', 'text/event-stream')
      res.setHeader('Cache-Control', 'no-cache')
      res.setHeader('Connection', 'keep-alive')
      res.setHeader('X-Accel-Buffering', 'no')
      res.flushHeaders()

      // ì‹œì‘ ì´ë²¤íŠ¸ ì „ì†¡
      res.write(`data: ${JSON.stringify({ type: 'start', messageCount: messages.length })}\n\n`)

      let fullResponse = ''

      try {
        const stream = this.aiService.generateChatResponseStream(messages, {
          temperature,
          maxTokens,
        })

        for await (const chunk of stream) {
          fullResponse += chunk
          res.write(`data: ${JSON.stringify({ type: 'chunk', content: chunk })}\n\n`)
        }

        // ì™„ë£Œ ì´ë²¤íŠ¸
        res.write(`data: ${JSON.stringify({ 
          type: 'done', 
          fullResponse,
          usage: {
            messageCount: messages.length,
            estimatedTokens: Math.ceil(fullResponse.length / 4)
          }
        })}\n\n`)

        logger.info('AI ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì™„ë£Œ', {
          userId,
          messageCount: messages.length,
          responseLength: fullResponse.length,
        })

      } catch (streamError) {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        logger.error('ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜:', streamError)
      }

      res.write('data: [DONE]\n\n')
      res.end()

    } catch (error) {
      logger.error('AI ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error)
      
      if (!res.headersSent) {
        res.status(500).json({
          success: false,
          error: 'ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        })
      } else {
        res.write(`data: ${JSON.stringify({ type: 'error', error: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })}\n\n`)
        res.end()
      }
    }
  }

  // í—¬í¼ ë©”ì„œë“œ: ìºë¦­í„° ì •ë³´ ì¡°íšŒ
  private async getCharacterById(characterId: string) {
    // ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
    // ì—¬ê¸°ì„œëŠ” ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜
    const sampleCharacters = {
      'sample_char_1': {
        id: 'sample_char_1',
        name: 'ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸',
        personality: 'í•­ìƒ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.',
        systemPrompt: 'ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ìµœëŒ€í•œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.',
        temperature: 0.7,
      },
      'sample_char_2': {
        id: 'sample_char_2',
        name: 'ì°½ì˜ì ì¸ ì‘ê°€',
        personality: 'ë‹¤ì–‘í•œ ì£¼ì œë¡œ ì°½ì˜ì ì¸ ê¸€ì„ ì“°ëŠ” AI ì‘ê°€ì…ë‹ˆë‹¤.',
        systemPrompt: 'ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì‘ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”.',
        temperature: 0.8,
      },
    }

    return sampleCharacters[characterId as keyof typeof sampleCharacters] || null
  }
}
